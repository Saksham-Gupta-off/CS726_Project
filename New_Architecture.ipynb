{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVz1k2uttFVo",
        "outputId": "703e0b3b-9ccd-47e1-e84e-b642cbec4747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mido in /usr/local/lib/python3.10/dist-packages (1.2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "Collecting h5py>=2.9.0\n",
            "  Using cached h5py-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Collecting keras<2.13,>=2.12.0\n",
            "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Using cached flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
            "Collecting packaging\n",
            "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Collecting numpy<1.24,>=1.22\n",
            "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Collecting tensorboard<2.13,>=2.12\n",
            "  Using cached tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Using cached tensorflow_io_gcs_filesystem-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "Collecting grpcio<2.0,>=1.24.3\n",
            "  Using cached grpcio-1.54.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "Collecting libclang>=13.0.0\n",
            "  Using cached libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
            "Collecting astunparse>=1.6.0\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting six>=1.12.0\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-67.7.2-py3-none-any.whl (1.1 MB)\n",
            "Collecting jax>=0.3.15\n",
            "  Using cached jax-0.4.8-py3-none-any.whl\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0\n",
            "  Using cached wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
            "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting absl-py>=1.0.0\n",
            "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
            "  Using cached protobuf-4.22.3-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "Collecting typing-extensions>=3.6.6\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting wheel<1.0,>=0.23.0\n",
            "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
            "Collecting ml-dtypes>=0.0.3\n",
            "  Using cached ml_dtypes-0.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (190 kB)\n",
            "Collecting scipy>=1.7\n",
            "  Using cached scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "Collecting requests<3,>=2.21.0\n",
            "  Using cached requests-2.29.0-py3-none-any.whl (62 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Using cached Werkzeug-2.3.3-py3-none-any.whl (242 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5\n",
            "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Using cached tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Using cached charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Using cached MarkupSafe-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6\n",
            "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, oauthlib, numpy, MarkupSafe, markdown, keras, idna, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, scipy, rsa, requests, pyasn1-modules, opt-einsum, ml-dtypes, h5py, google-pasta, astunparse, requests-oauthlib, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.1.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.0 h5py-3.8.0 idna-3.4 jax-0.4.8 keras-2.12.0 libclang-16.0.0 markdown-3.4.3 ml-dtypes-0.1.0 numpy-1.23.5 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-23.1 protobuf-4.22.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.29.0 requests-oauthlib-1.3.1 rsa-4.9 scipy-1.10.1 setuptools-67.7.2 six-1.16.0 tensorboard-2.12.2 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0 termcolor-2.3.0 typing-extensions-4.5.0 urllib3-1.26.15 werkzeug-2.3.3 wheel-0.40.0 wrapt-1.14.1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Found existing installation: numpy 1.23.5\n",
            "Uninstalling numpy-1.23.5:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.10\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy-1.23.5.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-742d56dc.3.20.so\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/*\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy-1.23.5.dist-info/REQUESTED\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/f2py/f2py_testing.py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_add_docstring.py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_array_like.py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_callable.pyi\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_char_codes.py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_dtype_like.py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_extended_precision.py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_generic_alias.py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_nbit.py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_nested_sequence.py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_scalars.py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_shape.py\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/typing/_ufunc.pyi\n",
            "Proceed (Y/n)? Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 160, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/uninstall.py\", line 105, in run\n",
            "    uninstall_pathset = req.uninstall(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_install.py\", line 664, in uninstall\n",
            "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 367, in remove\n",
            "    if auto_confirm or self._allowed_to_proceed(verbose):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 407, in _allowed_to_proceed\n",
            "    return ask(\"Proceed (Y/n)? \", (\"y\", \"n\", \"\")) != \"n\"\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 191, in ask\n",
            "    response = input(message)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 214, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 197, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 172, in emit\n",
            "    style = Style(color=\"red\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/style.py\", line 146, in __init__\n",
            "    def _make_color(color: Union[Color, str]) -> Color:\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 309, in inner\n",
            "    return cached(*args, **kwds)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 403, in __getitem__\n",
            "    return self._getitem(self, parameters)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 521, in Union\n",
            "    return _UnionGenericAlias(self, parameters)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 1016, in __init__\n",
            "    def __init__(self, origin, params, *, inst=True, name=None,\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23.*\n",
            "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3012, in _parsed_pkg_info\n",
            "    return self._pkg_info\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _pkg_info. Did you mean: 'egg_info'?\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 160, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 241, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 499, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 631, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3032, in _compute_dependencies\n",
            "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3014, in _parsed_pkg_info\n",
            "    metadata = self.get_metadata(self.PKG_INFO)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1419, in get_metadata\n",
            "    path = self._get_metadata_path(name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1407, in _get_metadata_path\n",
            "    return self._fn(self.egg_info, name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 1489, in _fn\n",
            "    return os.path.join(base, *resource_name.split('/'))\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 85, in join\n",
            "    elif not path or path.endswith(sep):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 214, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 198, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install mido\n",
        "!pip install tensorflow-addons\n",
        "!pip install --upgrade --ignore-installed tensorflow\n",
        "!pip install -q imageio\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y numpy\n",
        "!pip install numpy==1.23.* --ignore-installed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "3rJ07rxi67DO",
        "outputId": "154dea16-e5dd-4834-b811-6ea638627bf4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.23.5\n",
            "Uninstalling numpy-1.23.5:\n",
            "  Successfully uninstalled numpy-1.23.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23.*\n",
            "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/usr/local/lib/python3.10/dist-packages/numpy-1.23.5.dist-info/METADATA'\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: numpy\n",
            "Successfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import mido\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import librosa\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import time\n",
        "import IPython.display as ipd\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PgXq7ZptInS",
        "outputId": "a40c5f95-d95b-40fc-98e2-c2e6efaf30d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed=123\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "metadata": {
        "id": "8ECoq6ZbtR9i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeNeh7qDxyRF",
        "outputId": "d5b3915b-c03f-4815-a4bf-8b3dff4e96ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 60000\n",
        "BATCH_SIZE = 10\n",
        "test_size = 10000\n",
        "epochs = 20\n",
        "# set the dimensionality of the latent space to a plane for visualization later\n",
        "latent_dim = 2\n",
        "num_examples_to_generate = 10\n",
        "\n",
        "BASE_PATH = '/content/drive/My Drive/cs726_project/genres_original'"
      ],
      "metadata": {
        "id": "CmL-QK5pxPNR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DatasetLoader(class_):\n",
        "    music_list = np.array(sorted(os.listdir(BASE_PATH+'/'+class_)))\n",
        "    train_music_1 = list(music_list[[0,52,19,39,71,12,75,85,3,45,24,46,88]]) #99,10,66,76,41\n",
        "    train_music_2 = list(music_list[[4,43,56,55,45,31,11,13,70,37,21,78]]) #65,32,53,22,19,80,89,\n",
        "    TrackSet_1 = [(BASE_PATH)+'/'+class_+'/%s'%(x) for x in train_music_1]\n",
        "    TrackSet_2 = [(BASE_PATH)+'/'+class_+'/%s'%(x) for x in train_music_2]\n",
        "\n",
        "    return TrackSet_1, TrackSet_2"
      ],
      "metadata": {
        "id": "r-YuOAJ8yMgL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load(file_):\n",
        "    data, sampling_rate = librosa.load(file_,sr=3000, offset=0.0, duration=30)\n",
        "    data = data[0 : 75000]\n",
        "    data = data.reshape(100, 750)\n",
        "    data = tf.convert_to_tensor(data, dtype = tf.float32)\n",
        "    # data_ = data_[0 : 90000]\n",
        "    # data = []\n",
        "    # for i in range(120):\n",
        "    #   arg = tf.convert_to_tensor(data_[750*i:750*(i+1)], dtype = tf.float32)\n",
        "    #   arg = tf.reshape(arg, shape=(1, 750))\n",
        "    #   data.append(arg)\n",
        "    return data\n",
        "map_data = lambda filename: tf.compat.v1.py_func(load, [filename], tf.float32)"
      ],
      "metadata": {
        "id": "hzje8YBUyk1z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrackSet_1, TrackSet_2 = DatasetLoader('jazz')"
      ],
      "metadata": {
        "id": "oPqgUboG86Sk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samp = load(TrackSet_1[1])\n",
        "samp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fInzK5MxHW9l",
        "outputId": "82fe9e8b-88a0-4e02-e8ee-1b427f2bcfa9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 750), dtype=float32, numpy=\n",
              "array([[ 0.01675216,  0.07342426, -0.12623996, ..., -0.13352165,\n",
              "        -0.11601178, -0.01350737],\n",
              "       [-0.05094993, -0.11805218, -0.06304592, ..., -0.1811176 ,\n",
              "        -0.10112785,  0.01415266],\n",
              "       [-0.00813589,  0.02537277,  0.07389332, ..., -0.22472794,\n",
              "        -0.23269588, -0.28209594],\n",
              "       ...,\n",
              "       [ 0.031294  , -0.0033436 , -0.0111826 , ...,  0.07747798,\n",
              "        -0.00338306, -0.04828962],\n",
              "       [-0.01585888, -0.01529859,  0.04896452, ...,  0.21051843,\n",
              "         0.323723  ,  0.25154477],\n",
              "       [ 0.16953471,  0.08796553,  0.06990232, ...,  0.1895045 ,\n",
              "        -0.09651382, -0.15970421]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet1DBlock(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, kernel_size, filters, type='encode'):\n",
        "        super(Resnet1DBlock, self).__init__()\n",
        "        if type=='encode':\n",
        "            self.conv1a = layers.Conv1D(filters, kernel_size, 2,padding=\"same\")\n",
        "            self.conv1b = layers.Conv1D(filters, kernel_size, 1,padding=\"same\")\n",
        "            self.norm1a = tfa.layers.InstanceNormalization()\n",
        "            self.norm1b = tfa.layers.InstanceNormalization()\n",
        "        if type=='decode':\n",
        "            self.conv1a = layers.Conv1DTranspose(filters, kernel_size, 1,padding=\"same\")\n",
        "            self.conv1b = layers.Conv1DTranspose(filters, kernel_size, 1,padding=\"same\")\n",
        "            self.norm1a = tf.keras.layers.BatchNormalization()\n",
        "            self.norm1b = tf.keras.layers.BatchNormalization()\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        x = tf.nn.relu(input_tensor)\n",
        "        x = self.conv1a(x)\n",
        "        x = self.norm1a(x)\n",
        "        x = layers.LeakyReLU(0.4)(x)\n",
        "        x = self.conv1b(x)\n",
        "        x = self.norm1b(x)\n",
        "        x = layers.LeakyReLU(0.4)(x)\n",
        "        x += input_tensor\n",
        "        return tf.nn.relu(x)"
      ],
      "metadata": {
        "id": "INHN8Ualyoqq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = tf.keras.Sequential(\n",
        "            [\n",
        "                # layers.Reshape((1, 1), input_shape = (750, )),\n",
        "                tf.keras.layers.InputLayer(input_shape=(1,750)),\n",
        "                layers.Conv1D(64,1,2),\n",
        "                Resnet1DBlock(64,1),\n",
        "                layers.Conv1D(128,1,2),\n",
        "                Resnet1DBlock(128,1),\n",
        "                layers.Conv1D(128,1,2),\n",
        "                Resnet1DBlock(128,1),\n",
        "                layers.Conv1D(256,1,2),\n",
        "                Resnet1DBlock(256,1),\n",
        "                layers.Flatten(),\n",
        "                layers.Dense(2 * latent_dim)\n",
        "            ]\n",
        "        )\n",
        "        self.decoder = tf.keras.Sequential(\n",
        "            [\n",
        "                layers.InputLayer(input_shape=(latent_dim, )),\n",
        "                layers.Reshape(target_shape=(1, latent_dim)),\n",
        "                Resnet1DBlock(512, 1, 'decode'),\n",
        "                layers.Conv1DTranspose(512, 1, 1),\n",
        "                Resnet1DBlock(256, 1, 'decode'),\n",
        "                layers.Conv1DTranspose(256, 1, 1),\n",
        "                Resnet1DBlock(128, 1, 'decode'),\n",
        "                layers.Conv1DTranspose(128, 1, 1),\n",
        "                Resnet1DBlock(64, 1, 'decode'),\n",
        "                layers.Conv1DTranspose(64, 1, 1),\n",
        "                layers.Conv1DTranspose(750, 1, 1)\n",
        "            ]\n",
        "        )\n",
        "        self.next_state = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape = (latent_dim, )),\n",
        "                layers.Reshape(target_shape=(1, latent_dim)),\n",
        "                layers.Dense(256, activation = 'relu'),\n",
        "                layers.Dense(128, activation = 'relu'),\n",
        "                layers.Dense(latent_dim, activation = 'relu')\n",
        "            ]\n",
        "        )\n",
        "    @tf.function\n",
        "    def sample(self, eps=None):\n",
        "        if eps is None:\n",
        "            eps = tf.random.normal(shape=(200, self.latent_dim))\n",
        "        return self.decode(eps, apply_sigmoid=True)\n",
        "    @tf.function\n",
        "    def encode(self, x):\n",
        "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "    @tf.function\n",
        "    def reparametrize(self, mean, logvar):\n",
        "        eps = tf.random.normal(shape=mean.shape)\n",
        "        return eps * tf.exp(logvar * .5) + mean\n",
        "    @tf.function\n",
        "    def decode(self, z, apply_sigmoid=False):\n",
        "        logits = self.decoder(z)\n",
        "        if apply_sigmoid:\n",
        "            probs = tf.sigmoid(logits)\n",
        "            return probs\n",
        "        return logits\n",
        "    @tf.function\n",
        "    def get_next_state(self, z_prev):\n",
        "        return self.next_state(z_prev)"
      ],
      "metadata": {
        "id": "vLQG3ncJ1wV6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.legacy.Adam(0.0003,beta_1=0.9, beta_2=0.999,epsilon=1e-08)"
      ],
      "metadata": {
        "id": "viYSCw_62Ji5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "    log2pi = tf.math.log(2. * np.pi)\n",
        "    return tf.reduce_sum(\n",
        "         -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "          axis=raxis)"
      ],
      "metadata": {
        "id": "7mFyMuJ82cQn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_loss(model, test_sample):\n",
        "    total_loss = 0\n",
        "    for y in test_sample:\n",
        "        x = tf.reshape(y, shape = (1, 1, 750))\n",
        "        mean, logvar = model.encode(x)\n",
        "        z = model.reparametrize(mean, logvar)\n",
        "        x_logit = model.decode(z)\n",
        "        cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "        logpx_z = -tf.reduce_sum(cross_ent, axis=[1,2])\n",
        "        logpz = log_normal_pdf(z, 0., 0.)\n",
        "        logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "        total_loss -= tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "zG869wBG2gJE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "    x_prev = x[0]\n",
        "    x_prev = tf.reshape(x_prev, shape = (1, 1, 750))\n",
        "    net_loss = 0\n",
        "    # i = 0\n",
        "    for train_samp in x:\n",
        "        # if i == 0:\n",
        "        #     continue\n",
        "        train_sample = tf.reshape(train_samp, shape = (1, 1, 750))\n",
        "        with tf.GradientTape() as tape:\n",
        "            mean, logvar = model.encode(train_sample)\n",
        "            z = model.reparametrize(mean, logvar)\n",
        "            x_logit = model.decode(z)\n",
        "            cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits = x_logit, labels = train_sample)\n",
        "            logpx_z = -tf.reduce_sum(cross_ent, axis = [1,2])\n",
        "            logpz = log_normal_pdf(z, 0., 0.)\n",
        "            logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "            loss_KL = -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "            reconstruction_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(train_sample, x_logit))\n",
        "            mean_prev, logvar_prev = model.encode(x_prev)\n",
        "            z_prev = model.reparametrize(mean_prev, logvar_prev)\n",
        "            z_pred = model.get_next_state(z_prev)\n",
        "            z_recon_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(z, z_pred))\n",
        "            total_loss = reconstruction_loss + loss_KL + z_recon_loss\n",
        "        # print(\"Epoch \" + str(i + 1)  + \" : \" + \"Loss = \" + str(total_loss))\n",
        "        gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        # i += 1\n",
        "        # print(\"Epoch \" + str(i + 1) + \" done\")\n",
        "        x_prev = train_sample\n",
        "        # print(total_loss)\n",
        "        net_loss += total_loss\n",
        "    return net_loss"
      ],
      "metadata": {
        "id": "jrpF4yp32nr_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = (\n",
        "#     tf.data.Dataset\n",
        "#     .from_tensor_slices((TrackSet_1))\n",
        "#     .map(map_data, num_parallel_calls=AUTOTUNE)\n",
        "#     .shuffle(3)\n",
        "#     .batch(BATCH_SIZE)\n",
        "# )\n",
        "# test_dataset = (\n",
        "#     tf.data.Dataset\n",
        "#     .from_tensor_slices((TrackSet_2))\n",
        "#     .map(map_data, num_parallel_calls=AUTOTUNE)\n",
        "#     .shuffle(3)\n",
        "#     .batch(BATCH_SIZE)\n",
        "# )\n",
        "\n",
        "train_dataset = []\n",
        "\n",
        "for filename in TrackSet_1:\n",
        "    train_dataset.append(load(filename))\n",
        "\n",
        "train_dataset = tf.convert_to_tensor(train_dataset, dtype = tf.float32)\n",
        "\n",
        "test_dataset = []\n",
        "\n",
        "for filename in TrackSet_2:\n",
        "    test_dataset.append(load(filename))\n",
        "\n",
        "test_dataset = tf.convert_to_tensor(test_dataset, dtype = tf.float32)"
      ],
      "metadata": {
        "id": "2IZPZae_NjhF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HxCdh15qdtq",
        "outputId": "db4c7ed6-f770-4346-dc2c-3d7446ad5cdb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(13, 100, 750), dtype=float32, numpy=\n",
              "array([[[-0.00617013, -0.01385473, -0.01608861, ..., -0.02188793,\n",
              "         -0.00172184, -0.00077854],\n",
              "        [-0.00854354, -0.00394042, -0.0097504 , ...,  0.00419249,\n",
              "         -0.00260758, -0.0056454 ],\n",
              "        [ 0.00179191, -0.0011613 ,  0.00331267, ...,  0.01158473,\n",
              "          0.01928655,  0.01505182],\n",
              "        ...,\n",
              "        [-0.00381679, -0.00500411, -0.01123971, ..., -0.0058227 ,\n",
              "         -0.01284273, -0.02078624],\n",
              "        [-0.01516015, -0.00926865, -0.00189545, ..., -0.00598077,\n",
              "         -0.00934195, -0.01237829],\n",
              "        [-0.01336239, -0.01239097, -0.0142961 , ..., -0.02049899,\n",
              "         -0.01525505,  0.00053779]],\n",
              "\n",
              "       [[ 0.01675216,  0.07342426, -0.12623996, ..., -0.13352165,\n",
              "         -0.11601178, -0.01350737],\n",
              "        [-0.05094993, -0.11805218, -0.06304592, ..., -0.1811176 ,\n",
              "         -0.10112785,  0.01415266],\n",
              "        [-0.00813589,  0.02537277,  0.07389332, ..., -0.22472794,\n",
              "         -0.23269588, -0.28209594],\n",
              "        ...,\n",
              "        [ 0.031294  , -0.0033436 , -0.0111826 , ...,  0.07747798,\n",
              "         -0.00338306, -0.04828962],\n",
              "        [-0.01585888, -0.01529859,  0.04896452, ...,  0.21051843,\n",
              "          0.323723  ,  0.25154477],\n",
              "        [ 0.16953471,  0.08796553,  0.06990232, ...,  0.1895045 ,\n",
              "         -0.09651382, -0.15970421]],\n",
              "\n",
              "       [[-0.00325527, -0.00184376, -0.03070977, ..., -0.0415633 ,\n",
              "         -0.04246239, -0.02854121],\n",
              "        [-0.01508054, -0.0275129 , -0.05176579, ...,  0.04507987,\n",
              "          0.06866351,  0.05552996],\n",
              "        [ 0.06247336,  0.05380714,  0.08523735, ...,  0.03669419,\n",
              "          0.01369102,  0.01769516],\n",
              "        ...,\n",
              "        [ 0.09543127,  0.05238049,  0.01632183, ..., -0.02031024,\n",
              "         -0.0054639 , -0.00775331],\n",
              "        [-0.00948325,  0.02837356,  0.01782674, ...,  0.0753886 ,\n",
              "          0.05182894,  0.10021397],\n",
              "        [ 0.10582097,  0.08967421,  0.0509606 , ...,  0.0074544 ,\n",
              "          0.00059113, -0.02352747]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-0.02050137, -0.07479187, -0.02491478, ...,  0.08236941,\n",
              "         -0.08495441, -0.0139129 ],\n",
              "        [-0.06156043,  0.03747305,  0.00552723, ...,  0.04846122,\n",
              "         -0.04123663, -0.01186611],\n",
              "        [-0.0344143 , -0.012248  , -0.032328  , ...,  0.01883934,\n",
              "          0.02312901,  0.11947194],\n",
              "        ...,\n",
              "        [-0.05190734, -0.0408292 , -0.05789063, ..., -0.01623522,\n",
              "         -0.01580692, -0.00997469],\n",
              "        [-0.00922074, -0.0380106 ,  0.03662403, ...,  0.02576581,\n",
              "         -0.04385117, -0.03736594],\n",
              "        [-0.05854533, -0.01964802, -0.03457287, ..., -0.16620782,\n",
              "         -0.07113551, -0.03705191]],\n",
              "\n",
              "       [[-0.02160869, -0.04209656, -0.08790477, ..., -0.04355819,\n",
              "          0.00435662,  0.03919606],\n",
              "        [ 0.02199527,  0.06238176, -0.00373239, ..., -0.05772882,\n",
              "         -0.01504838,  0.02889865],\n",
              "        [ 0.0385223 ,  0.03018289, -0.040267  , ..., -0.06639214,\n",
              "          0.02516245,  0.03837451],\n",
              "        ...,\n",
              "        [-0.13520357,  0.03324888,  0.1955373 , ..., -0.27892026,\n",
              "         -0.04546969,  0.14046398],\n",
              "        [ 0.32158217,  0.1164715 , -0.22743809, ...,  0.1636666 ,\n",
              "          0.157702  , -0.07352726],\n",
              "        [-0.18190624, -0.0283701 ,  0.17909256, ...,  0.17376485,\n",
              "          0.15672205,  0.16011055]],\n",
              "\n",
              "       [[-0.01104831,  0.03145271,  0.06803166, ..., -0.15814422,\n",
              "         -0.13521044, -0.04358946],\n",
              "        [ 0.06257527,  0.20796463,  0.07659258, ...,  0.24576038,\n",
              "          0.11102159, -0.14916284],\n",
              "        [ 0.01974382, -0.04248016, -0.12622242, ..., -0.04180197,\n",
              "         -0.12793243, -0.0055991 ],\n",
              "        ...,\n",
              "        [ 0.11116686, -0.00817873, -0.08479355, ..., -0.00901348,\n",
              "         -0.06278995, -0.06712192],\n",
              "        [-0.00545874,  0.01193324,  0.01054745, ...,  0.1380758 ,\n",
              "          0.02752462, -0.0037385 ],\n",
              "        [ 0.0730674 ,  0.19445346,  0.07030731, ..., -0.03553557,\n",
              "         -0.06079853, -0.01231475]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB47-xiualnj",
        "outputId": "908ac86f-6aac-44dc-df7a-23fec3dba626"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(12, 100, 750), dtype=float32, numpy=\n",
              "array([[[ 0.09052681,  0.26096714,  0.03838222, ...,  0.09505847,\n",
              "         -0.22011402, -0.22248815],\n",
              "        [ 0.18683311,  0.24498484, -0.01537771, ...,  0.13771997,\n",
              "         -0.15418467, -0.07472448],\n",
              "        [ 0.1431193 , -0.08900037, -0.31396025, ..., -0.17313775,\n",
              "          0.00424118,  0.11987076],\n",
              "        ...,\n",
              "        [ 0.0323396 , -0.01239425, -0.06534199, ..., -0.06615368,\n",
              "         -0.0652673 , -0.01371949],\n",
              "        [ 0.05025498, -0.07314209, -0.03657861, ..., -0.01311526,\n",
              "         -0.02016663,  0.00291737],\n",
              "        [-0.01262713, -0.06105466, -0.10576949, ..., -0.16231762,\n",
              "          0.02938618,  0.07584637]],\n",
              "\n",
              "       [[-0.05478245, -0.11190942, -0.08331225, ..., -0.05193736,\n",
              "          0.08008962,  0.13153963],\n",
              "        [ 0.10029635,  0.02166242, -0.09242068, ..., -0.04909403,\n",
              "         -0.07831205, -0.10820825],\n",
              "        [-0.08485813, -0.03404973, -0.03481009, ...,  0.03372068,\n",
              "         -0.12679571, -0.00947391],\n",
              "        ...,\n",
              "        [ 0.06477296,  0.11817759,  0.13051277, ..., -0.08663414,\n",
              "          0.03448164,  0.09715628],\n",
              "        [-0.01005672, -0.02612006, -0.0756557 , ...,  0.24414784,\n",
              "          0.1449141 ,  0.03078547],\n",
              "        [-0.00243163,  0.05831911, -0.12877315, ...,  0.13847256,\n",
              "          0.18576485, -0.04217717]],\n",
              "\n",
              "       [[ 0.01480213,  0.01807299,  0.09204413, ...,  0.05078643,\n",
              "          0.03026352, -0.09232201],\n",
              "        [-0.21593751, -0.27411923, -0.20611924, ...,  0.3374955 ,\n",
              "          0.36559808,  0.3209376 ],\n",
              "        [ 0.2298366 ,  0.09139841, -0.00508092, ...,  0.18989286,\n",
              "          0.23462257,  0.32649937],\n",
              "        ...,\n",
              "        [-0.10813831,  0.05202946,  0.15598421, ..., -0.06665375,\n",
              "          0.03121991,  0.00073123],\n",
              "        [ 0.14369655,  0.23793644,  0.17000474, ...,  0.12752958,\n",
              "          0.06782809,  0.31504014],\n",
              "        [ 0.05708034, -0.0883476 , -0.07410984, ..., -0.3423794 ,\n",
              "         -0.00255975,  0.07816295]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.00638674, -0.03948389, -0.03077064, ..., -0.38762197,\n",
              "         -0.39183888, -0.18298611],\n",
              "        [-0.33675116, -0.21739793, -0.03306699, ...,  0.0087754 ,\n",
              "         -0.0191133 , -0.08255182],\n",
              "        [-0.02007256, -0.04864222, -0.04837109, ..., -0.00983359,\n",
              "         -0.05006726, -0.07209567],\n",
              "        ...,\n",
              "        [ 0.14282179,  0.03038946, -0.0137163 , ..., -0.12623386,\n",
              "          0.03057725,  0.01120355],\n",
              "        [-0.05047631, -0.02378487, -0.06551449, ...,  0.05065529,\n",
              "          0.02830165,  0.02929917],\n",
              "        [ 0.13416189,  0.11527658,  0.0361427 , ..., -0.05792886,\n",
              "         -0.06972957, -0.02207972]],\n",
              "\n",
              "       [[-0.00234212,  0.00580404, -0.01111337, ..., -0.06783001,\n",
              "         -0.04762587, -0.00322513],\n",
              "        [-0.00075556, -0.0321656 , -0.02615135, ..., -0.00531483,\n",
              "         -0.0163926 , -0.02070635],\n",
              "        [-0.01769123,  0.00175014,  0.00831511, ..., -0.00569797,\n",
              "         -0.00054234,  0.00494598],\n",
              "        ...,\n",
              "        [ 0.02429297,  0.07441537,  0.09592797, ...,  0.04721542,\n",
              "          0.05021343,  0.02960828],\n",
              "        [ 0.02313088,  0.03363763,  0.0398938 , ..., -0.00234435,\n",
              "          0.00792555,  0.00839325],\n",
              "        [ 0.01670825,  0.02316421,  0.01166538, ..., -0.05632095,\n",
              "         -0.12481289, -0.03741902]],\n",
              "\n",
              "       [[ 0.0607353 ,  0.10612319,  0.11521974, ...,  0.04959109,\n",
              "          0.0653559 ,  0.05579579],\n",
              "        [ 0.13901748,  0.2153693 ,  0.18502599, ...,  0.0021566 ,\n",
              "          0.00102861,  0.00363716],\n",
              "        [-0.00725862, -0.0248731 , -0.03982217, ...,  0.00314102,\n",
              "         -0.00374211, -0.01068953],\n",
              "        ...,\n",
              "        [-0.22178492, -0.12390748,  0.35130668, ...,  0.07512622,\n",
              "          0.0898018 ,  0.09383419],\n",
              "        [ 0.10306935,  0.1115623 ,  0.06249093, ..., -0.0818138 ,\n",
              "         -0.08090942, -0.18897316],\n",
              "        [-0.11694978, -0.04636332, -0.09507245, ...,  0.08290146,\n",
              "          0.09082419,  0.03602435]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataset, test_dataset, model):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        start_time = time.time()\n",
        "        for train_x in train_dataset:\n",
        "            # train_x = np.asarray(train_x)[0][0]\n",
        "            print(train_step(model, train_x, optimizer))\n",
        "        end_time = time.time()\n",
        "\n",
        "        # loss = tf.keras.metrics.Mean()\n",
        "        # for test_x in test_dataset:\n",
        "        #     test_x = np.asarray(test_x)[0][0]\n",
        "        #     loss(compute_loss(model, test_x))\n",
        "        # display.clear_output(wait=False)\n",
        "        # elbo = -loss.result()\n",
        "        # print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'.format(epoch, \n",
        "        #                                                                                elbo, \n",
        "        #                                                                                end_time - start_time\n",
        "        #                                                                                ))"
      ],
      "metadata": {
        "id": "SZ8f4tCtoNwr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(300)\n",
        "train(train_dataset, test_dataset, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfErZLS9oxID",
        "outputId": "620db017-355d-4be8-fc0c-ebdb23192394"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(13336.957, shape=(), dtype=float32)\n",
            "tf.Tensor(-7537.989, shape=(), dtype=float32)\n",
            "tf.Tensor(7760.1494, shape=(), dtype=float32)\n",
            "tf.Tensor(-879492.1, shape=(), dtype=float32)\n",
            "tf.Tensor(1830974500.0, shape=(), dtype=float32)\n",
            "tf.Tensor(124570060.0, shape=(), dtype=float32)\n",
            "tf.Tensor(-1874017700.0, shape=(), dtype=float32)\n",
            "tf.Tensor(10935370000000.0, shape=(), dtype=float32)\n",
            "tf.Tensor(677409800000000.0, shape=(), dtype=float32)\n",
            "tf.Tensor(47914732.0, shape=(), dtype=float32)\n",
            "tf.Tensor(57097020.0, shape=(), dtype=float32)\n",
            "tf.Tensor(-85948840.0, shape=(), dtype=float32)\n",
            "tf.Tensor(142123410.0, shape=(), dtype=float32)\n",
            "tf.Tensor(4104585.5, shape=(), dtype=float32)\n",
            "tf.Tensor(-1239362600.0, shape=(), dtype=float32)\n",
            "tf.Tensor(4220692.5, shape=(), dtype=float32)\n",
            "tf.Tensor(115212.57, shape=(), dtype=float32)\n",
            "tf.Tensor(-3719217.8, shape=(), dtype=float32)\n",
            "tf.Tensor(7256192.0, shape=(), dtype=float32)\n",
            "tf.Tensor(-10506462.0, shape=(), dtype=float32)\n",
            "tf.Tensor(378643.94, shape=(), dtype=float32)\n",
            "tf.Tensor(903592.4, shape=(), dtype=float32)\n",
            "tf.Tensor(1145238.8, shape=(), dtype=float32)\n",
            "tf.Tensor(1037626.06, shape=(), dtype=float32)\n",
            "tf.Tensor(1865293.8, shape=(), dtype=float32)\n",
            "tf.Tensor(-2480716.5, shape=(), dtype=float32)\n",
            "tf.Tensor(1448953.2, shape=(), dtype=float32)\n",
            "tf.Tensor(-1001505860.0, shape=(), dtype=float32)\n",
            "tf.Tensor(11750848.0, shape=(), dtype=float32)\n",
            "tf.Tensor(-6718843.5, shape=(), dtype=float32)\n",
            "tf.Tensor(-81223496.0, shape=(), dtype=float32)\n",
            "tf.Tensor(20097074.0, shape=(), dtype=float32)\n",
            "tf.Tensor(-446151970.0, shape=(), dtype=float32)\n",
            "tf.Tensor(8164901.5, shape=(), dtype=float32)\n",
            "tf.Tensor(4366440.5, shape=(), dtype=float32)\n",
            "tf.Tensor(-588837250.0, shape=(), dtype=float32)\n",
            "tf.Tensor(122585816.0, shape=(), dtype=float32)\n",
            "tf.Tensor(-1505611900.0, shape=(), dtype=float32)\n",
            "tf.Tensor(-9726728000.0, shape=(), dtype=float32)\n",
            "tf.Tensor(-2640130300.0, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n",
            "tf.Tensor(nan, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uWy7LsU806VO"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}